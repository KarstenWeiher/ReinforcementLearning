{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1=array([[-0.15893564,  0.13024658, -0.11753192, -0.14273552, -0.08926084,\n",
      "        -0.38934029,  0.04215685,  0.33183259, -0.01957468],\n",
      "       [ 0.01818512, -0.17570159,  0.71097321, -0.05210045, -0.03237064,\n",
      "        -0.46694079,  0.03334698, -0.26382745,  0.30948366],\n",
      "       [ 0.46908631,  0.73161488, -0.07080723, -0.58263723, -0.21744845,\n",
      "        -0.02169667, -0.13139818, -0.0646271 ,  0.34550623],\n",
      "       [-0.13388643, -0.0874081 , -0.29522438,  0.61991822, -0.25045293,\n",
      "        -0.29769936, -0.21374882, -0.1361205 , -0.2994686 ],\n",
      "       [ 0.65545645,  0.16517154,  0.25986713, -0.04452332,  0.19452173,\n",
      "        -0.30758339, -0.46939769,  0.26410541, -0.34668873],\n",
      "       [-0.16176667, -0.11509238,  0.16555023,  0.12605055,  0.2009971 ,\n",
      "         0.07635315,  0.0564335 , -0.67768758, -0.14939983],\n",
      "       [ 0.57444312,  0.12010707, -0.07575461,  0.59967204,  0.19016486,\n",
      "        -0.0134451 ,  0.10441614, -0.49036446, -0.26923222],\n",
      "       [ 0.16593601, -0.18524726, -0.04499084, -0.52225069,  0.14847422,\n",
      "         0.14446418, -0.47416323,  0.56620002, -0.49184877],\n",
      "       [ 0.86437237,  0.21411346, -0.09439954, -0.13040295, -0.00274091,\n",
      "         0.09312484, -0.06758074, -0.18568218, -0.03725866]])\n",
      " b1=array([ 0.68017748, -0.16887597, -0.57760693,  0.50621592, -0.09387825,\n",
      "       -0.29067814,  0.03606161,  0.02769636, -0.1152186 ])\n"
     ]
    }
   ],
   "source": [
    "# initialize NN and set parameters\n",
    "input_size = 9 \n",
    "output_size = 9\n",
    "epsilon = 0.3 # Probabilty to take random actions\n",
    "gamma = 0.7 # Discount factor\n",
    "learning_rate = 1e-3\n",
    "\n",
    "W1 = np.random.randn(input_size, output_size) / np.sqrt(output_size)\n",
    "b1 = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "def forward_pass(x):\n",
    "    return np.dot(x,W1) + b1\n",
    "\n",
    "def backward_pass(x, y_diff):\n",
    "    \n",
    "\n",
    "    pass\n",
    "\n",
    "def get_propabilities(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "print(f'{W1=}\\n {b1=}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits=array([-0.86497345, -0.17375046,  1.28968619, -0.81365114,  0.08738364,\n",
      "        0.96772606, -0.4105061 ,  0.460592  , -0.62226655])\n",
      " probabilities=array([0.0355484 , 0.07096012, 0.3066033 , 0.03742045, 0.09213475,\n",
      "       0.22220371, 0.0560006 , 0.13381531, 0.04531336])\n"
     ]
    }
   ],
   "source": [
    "dummy_x = np.random.randn(9)\n",
    "\n",
    "logits = forward_pass(dummy_x)\n",
    "probabilities = get_propabilities(logits)\n",
    "print(f'{logits=}\\n {probabilities=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(s):\n",
    "    x = ['-', 'x', 'o']\n",
    "    print(f' [{x[s[0]]} {x[s[1]]} {x[s[2]]}] \\n [{x[s[3]]} {x[s[4]]} {x[s[5]]}] \\n [{x[s[6]]} {x[s[7]]} {x[s[8]]}] \\n')\n",
    "\n",
    "def get_discounted_rewards(actions, reward):\n",
    "    rewards = [reward * gamma**i for i in range(len(actions))]\n",
    "    return rewards[::-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define game loop. Start with the Ai always starting and the opponent going second\n",
    "ai_token = 1\n",
    "opponent_token = 2\n",
    "\n",
    "def take_random_action(board, token):\n",
    "    free_indices = [i for i, val in enumerate(board) if val == 0]\n",
    "    action = np.random.choice(free_indices)\n",
    "    board[action] = token\n",
    "    return action, board\n",
    "\n",
    "def take_action(board, logits, token):\n",
    "    if epsilon > np.random.random_sample():\n",
    "        action, board = take_random_action(board, token)\n",
    "    else:\n",
    "        free_indices = [i for i, val in enumerate(board) if val == 0]\n",
    "        l_free = logits[free_indices] # get logits of possible moves\n",
    "        p = get_propabilities(l_free)\n",
    "        action = np.random.choice(free_indices, p=p)\n",
    "        board[action] = token\n",
    "    return action, board\n",
    "\n",
    "def check_winner(board):\n",
    "\n",
    "    winning_combinations = [\n",
    "        (0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "        (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "        (0, 4, 8), (2, 4, 6)\n",
    "    ]\n",
    "    for combo in winning_combinations:\n",
    "        if board[combo[0]] == board[combo[1]] == board[combo[2]] != 0:\n",
    "            return board[combo[0]] \n",
    "    return 0\n",
    "\n",
    "def get_reward(winner):\n",
    "    if winner == ai_token:\n",
    "        return 1\n",
    "    elif winner == opponent_token:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def play_game():\n",
    "    board = [0] * 9\n",
    "    boards_arr = []\n",
    "    actions_arr = []\n",
    "    logits_arr = []\n",
    "    for t in range(9):\n",
    "        if t%2 == 0:\n",
    "            boards_arr.append(board.copy())\n",
    "            logits = forward_pass(board)\n",
    "            action, board = take_action(board, logits, ai_token)\n",
    "            actions_arr.append(action) \n",
    "            logits_arr.append(logits)\n",
    "        else:\n",
    "            action, board = take_random_action(board, opponent_token)   \n",
    "        winner = check_winner(board)\n",
    "        reward = get_reward(winner)\n",
    "        if reward:\n",
    "            break    \n",
    "    return boards_arr, actions_arr, logits_arr, reward\n",
    "\n",
    "boards, actions, logits, reward = play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48999999999999994, 0.7, 1.0]\n"
     ]
    }
   ],
   "source": [
    "rewards = get_discounted_rewards(actions, reward)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions=[2, 6, 4] \n",
      " logits=[array([ 0.06571969, -0.08514417,  0.81530028, -0.37766099, -0.16058463,\n",
      "       -0.34139338,  0.39587798,  0.51943669, -0.60444246]), array([ 1.52537055, -0.03882505,  0.69816536, -0.36037973,  0.24198805,\n",
      "       -1.57083642,  1.1833322 ,  0.40794881, -0.15951308]), array([ 1.88353529, -1.69761012,  0.39188013, -0.5382177 ,  1.54938948,\n",
      "       -1.37590337,  2.78663691,  0.36361585, -1.01436872])]\n"
     ]
    }
   ],
   "source": [
    "print(f'{actions=} \\n {logits=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 9)\n",
      "(41, 9)\n",
      "(41,)\n"
     ]
    }
   ],
   "source": [
    "episodes = 2 # Do 10 training episodes\n",
    "n = 10 # play 1000 games\n",
    "\n",
    "def get_ydiff(logits, actions):\n",
    "    y_diff = []\n",
    "    for lg, a in zip(logits, actions):\n",
    "        act_arr = [0] * 9\n",
    "        act_arr[a] = 1\n",
    "        y_diff.append(act_arr - get_propabilities(lg))\n",
    "    return y_diff\n",
    "\n",
    "for e in range(episodes):\n",
    "    X, y_diff, R = [], [], [] # X : Training Data of board states, y_diff Difference between action taken and output probabilities\n",
    "    # R: Rewards for the (X,y) samples\n",
    "    for i in range(n):\n",
    "        boards, actions, logits, reward = play_game()\n",
    "        rewards = get_discounted_rewards(actions, reward)\n",
    "        diff = get_ydiff(logits, actions)\n",
    "\n",
    "        X.append(boards)\n",
    "        y_diff.append(diff)\n",
    "        R.append(rewards)\n",
    "\n",
    "    # reduce dimensionality to avoid problems with different game length\n",
    "    Xeps = np.array([b for g in X for b in g]) \n",
    "    yeps = np.array([y for g in y_diff for y in g])\n",
    "    Reps = np.array([r for g in R for r in g])\n",
    "\n",
    "    # normalize the rewards\n",
    "    Reps -= np.mean(Reps)\n",
    "    Reps /= np.std(Reps)\n",
    "\n",
    "    yeps *= Reps[:, np.newaxis] # mutiply gradient and reward\n",
    "\n",
    "    dW, db = backward_pass(yeps)\n",
    "    W1 += learning_rate*dW\n",
    "    b1 += learning_rate*db\n",
    "\n",
    "print(Xeps.shape)\n",
    "print(yeps.shape)\n",
    "print(Reps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.343   0.49    0.7     1.     -0.343  -0.49   -0.7    -1.      0.2401\n",
      "  0.343   0.49    0.7     1.      0.49    0.7     1.      0.      0.\n",
      "  0.      0.      0.      0.343   0.49    0.7     1.     -0.343  -0.49\n",
      " -0.7    -1.     -0.343  -0.49   -0.7    -1.      0.343   0.49    0.7\n",
      "  1.      0.343   0.49    0.7     1.    ]\n",
      "[ 0.26306186  0.504496    0.84940192  1.34212465 -0.86363079 -1.10506493\n",
      " -1.44997084 -1.94269357  0.09405797  0.26306186  0.504496    0.84940192\n",
      "  1.34212465  0.504496    0.84940192  1.34212465 -0.30028446 -0.30028446\n",
      " -0.30028446 -0.30028446 -0.30028446  0.26306186  0.504496    0.84940192\n",
      "  1.34212465 -0.86363079 -1.10506493 -1.44997084 -1.94269357 -0.86363079\n",
      " -1.10506493 -1.44997084 -1.94269357  0.26306186  0.504496    0.84940192\n",
      "  1.34212465  0.26306186  0.504496    0.84940192  1.34212465]\n"
     ]
    }
   ],
   "source": [
    "print(Reps)\n",
    "R_n = Reps - np.mean(Reps)\n",
    "R_n /= np.std(R_n)\n",
    "print(R_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
