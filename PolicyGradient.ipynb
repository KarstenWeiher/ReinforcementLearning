{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NN and set parameters\n",
    "input_size = 9 \n",
    "output_size = 9\n",
    "epsilon = 0.0 # Probabilty to take random actions\n",
    "gamma = 0.7 # Discount factor\n",
    "learning_rate = 1e-3\n",
    "\n",
    "W1 = np.random.randn(input_size, output_size) / np.sqrt(output_size)\n",
    "b1 = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "def forward_pass(x):\n",
    "    return np.dot(x,W1) + b1\n",
    "\n",
    "def backward_pass(X, Y_diff):\n",
    "    dW = np.dot(X.T,Y_diff)\n",
    "    db = np.mean(Y_diff, axis = 0)\n",
    "    return dW, db\n",
    "\n",
    "def get_propabilities(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "#print(f'{W1=}\\n {b1=}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    def __init__(self, hl_size = 9):\n",
    "        self.W1 = np.random.randn(output_size, input_size) / np.sqrt(input_size)\n",
    "        self.b1 = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        x1 =  np.dot(self.W1, x) + self.b1\n",
    "        return x1\n",
    "    \n",
    "    def backward_pass(self, X, Y_diff):\n",
    "        dW = np.dot(X.T,Y_diff)\n",
    "        db = np.mean(Y_diff, axis = 0)\n",
    "        return {'W1':dW, 'b1':db}\n",
    "    \n",
    "    def get_propabilities(self, x):\n",
    "        return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonlinearModel:\n",
    "    def __init__(self, hl_size = 9):\n",
    "        self.W1 = np.random.randn(hl_size, input_size) / np.sqrt(input_size)\n",
    "        self.W2 = np.random.randn(output_size, hl_size) / np.sqrt(hl_size)\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        x1 =  np.dot(self.W1, x) \n",
    "        x1[x1 < 0] = 0 # relu\n",
    "        x2 = np.dot(self.W2, x1)\n",
    "        return x2, x1\n",
    "    \n",
    "    def backward_pass(self, X, H, Y_diff):\n",
    "        dW2 = np.dot(H.T, Y_diff).ravel()\n",
    "        dh = np.outer(Y_diff, self.W2)\n",
    "        dh[H <= 0] = 0 # backpro prelu\n",
    "        dW1 = np.dot(dh.T, X)\n",
    "        return {'W1':dW1, 'W2':dW2}\n",
    "    \n",
    "    def get_propabilities(self, x):\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits=array([-0.73663234,  1.68002054,  1.49501772,  0.00455982,  0.80650807,\n",
      "        0.54566942,  0.65658166, -1.5193994 , -0.70114445])\n",
      " probabilities=array([0.02671856, 0.29946911, 0.24888935, 0.05606718, 0.12502313,\n",
      "       0.09631847, 0.10761633, 0.0122141 , 0.02768377])\n"
     ]
    }
   ],
   "source": [
    "dummy_x = np.random.randn(9)\n",
    "\n",
    "logits = forward_pass(dummy_x)\n",
    "probabilities = get_propabilities(logits)\n",
    "print(f'{logits=}\\n {probabilities=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(s):\n",
    "    x = ['-', 'x', 'o']\n",
    "    print(f' [{x[s[0]]} {x[s[1]]} {x[s[2]]}] \\n [{x[s[3]]} {x[s[4]]} {x[s[5]]}] \\n [{x[s[6]]} {x[s[7]]} {x[s[8]]}] \\n')\n",
    "\n",
    "def get_discounted_rewards(actions, reward):\n",
    "    rewards = [reward * gamma**i for i in range(len(actions))]\n",
    "    return rewards[::-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define game loop. Start with the Ai always starting and the opponent going second\n",
    "ai_token = 1\n",
    "opponent_token = 2\n",
    "\n",
    "def take_random_action(board, token):\n",
    "    free_indices = [i for i, val in enumerate(board) if val == 0]\n",
    "    action = np.random.choice(free_indices)\n",
    "    board[action] = token\n",
    "    return action, board\n",
    "\n",
    "def take_action(board, logits, token):\n",
    "    if epsilon > np.random.random_sample():\n",
    "        action, board = take_random_action(board, token)\n",
    "    else:\n",
    "        free_indices = [i for i, val in enumerate(board) if val == 0]\n",
    "        l_free = logits[free_indices] # get logits of possible moves\n",
    "        p = get_propabilities(l_free)\n",
    "        action = np.random.choice(free_indices, p=p)\n",
    "        board[action] = token\n",
    "    return action, board\n",
    "\n",
    "def check_winner(board):\n",
    "\n",
    "    winning_combinations = [\n",
    "        (0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "        (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "        (0, 4, 8), (2, 4, 6)\n",
    "    ]\n",
    "    for combo in winning_combinations:\n",
    "        if board[combo[0]] == board[combo[1]] == board[combo[2]] != 0:\n",
    "            return board[combo[0]] \n",
    "    return 0\n",
    "\n",
    "def get_reward(winner):\n",
    "    if winner == ai_token:\n",
    "        return 1\n",
    "    elif winner == opponent_token:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def play_game(verbose = False):\n",
    "    board = [0] * 9\n",
    "    boards_arr = []\n",
    "    actions_arr = []\n",
    "    logits_arr = []\n",
    "    for t in range(9):\n",
    "        if t%2 == 0:\n",
    "            boards_arr.append(board.copy())\n",
    "            logits = forward_pass(board)\n",
    "            action, board = take_action(board, logits, ai_token)\n",
    "            actions_arr.append(action) \n",
    "            logits_arr.append(logits)\n",
    "        else:\n",
    "            action, board = take_random_action(board, opponent_token)   \n",
    "        winner = check_winner(board)\n",
    "        reward = get_reward(winner)\n",
    "        if verbose:\n",
    "            print_board(board)\n",
    "        if reward:\n",
    "            break    \n",
    "    return boards_arr, actions_arr, logits_arr, reward\n",
    "\n",
    "boards, actions, logits, reward = play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rewards = get_discounted_rewards(actions, reward)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions=[np.int64(8), np.int64(6), np.int64(1), np.int64(3), np.int64(5)] \n",
      " logits=[array([-0.24099705,  0.13863381, -0.13835625,  0.33455209,  0.08784616,\n",
      "        0.29888912,  0.56022063, -0.08711018,  0.22725257]), array([-1.69209372, -0.249083  ,  0.05398859, -0.47040208, -0.14453246,\n",
      "       -0.03746941,  0.61012092, -0.61968493, -1.43690049]), array([-1.78871478, -0.25637051, -0.85152251, -0.15397983,  0.80712391,\n",
      "       -0.12914771,  0.64956039,  0.201317  , -2.50482501]), array([-1.9241332 , -0.20261841, -0.0610732 , -0.29182636,  1.10871276,\n",
      "       -0.51740419,  0.00783651,  0.6875912 , -1.97572366]), array([-1.94186841,  0.08769638, -0.76587041, -0.19434156,  0.75114375,\n",
      "       -0.06317836, -0.03367245,  1.09518468, -1.10606512])]\n"
     ]
    }
   ],
   "source": [
    "print(f'{actions=} \\n {logits=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.281\n",
      "0.302\n",
      "0.415\n",
      "0.355\n",
      "0.336\n",
      "0.399\n",
      "0.423\n",
      "0.469\n",
      "0.415\n",
      "0.475\n",
      "(4046, 9)\n",
      "(4046, 9)\n",
      "(4046,)\n"
     ]
    }
   ],
   "source": [
    "episodes = 10 # Do 10 training episodes\n",
    "n = 1000 # play 1000 games\n",
    "\n",
    "def get_ydiff(logits, actions):\n",
    "    y_diff = []\n",
    "    for lg, a in zip(logits, actions):\n",
    "        act_arr = [0] * 9\n",
    "        act_arr[a] = 1\n",
    "        y_diff.append(act_arr - get_propabilities(lg))\n",
    "    return y_diff\n",
    "\n",
    "for e in range(episodes):\n",
    "    X, y_diff, R = [], [], [] # X : Training Data of board states, y_diff Difference between action taken and output probabilities\n",
    "    R_sum = 0\n",
    "    # R: Rewards for the (X,y) samples\n",
    "    for i in range(n):\n",
    "        boards, actions, logits, reward = play_game()\n",
    "        rewards = get_discounted_rewards(actions, reward)\n",
    "        diff = get_ydiff(logits, actions)\n",
    "\n",
    "        X.append(boards)\n",
    "        y_diff.append(diff)\n",
    "        R.append(rewards)\n",
    "        R_sum += reward\n",
    "\n",
    "    # reduce dimensionality to avoid problems with different game length\n",
    "    Xeps = np.array([b for g in X for b in g]) \n",
    "    yeps = np.array([y for g in y_diff for y in g])\n",
    "    Reps = np.array([r for g in R for r in g])\n",
    "\n",
    "    # normalize the rewards\n",
    "    Reps -= np.mean(Reps)\n",
    "    Reps /= np.std(Reps)\n",
    "\n",
    "    yeps *= Reps[:, np.newaxis] # mutiply gradient and reward\n",
    "\n",
    "    dW, db = backward_pass(Xeps, yeps)\n",
    "    W1 += learning_rate*dW\n",
    "    b1 += learning_rate*db\n",
    "\n",
    "    print(R_sum/n)\n",
    "\n",
    "print(Xeps.shape)\n",
    "print(yeps.shape)\n",
    "print(Reps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10333687, 0.15810862, 0.14699808, 0.08881846, 0.13631235,\n",
       "       0.0741378 , 0.11383991, 0.05616346, 0.12228444])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = [0] * 9\n",
    "board[3] = 1\n",
    "board[1] = 2\n",
    "logits = forward_pass(board)\n",
    "probs = get_propabilities(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [- - -] \n",
      " [- - -] \n",
      " [- - x] \n",
      "\n",
      " [- - -] \n",
      " [- - -] \n",
      " [- o x] \n",
      "\n",
      " [- - -] \n",
      " [- x -] \n",
      " [- o x] \n",
      "\n",
      " [- o -] \n",
      " [- x -] \n",
      " [- o x] \n",
      "\n",
      " [- o x] \n",
      " [- x -] \n",
      " [- o x] \n",
      "\n",
      " [- o x] \n",
      " [- x -] \n",
      " [o o x] \n",
      "\n",
      " [x o x] \n",
      " [- x -] \n",
      " [o o x] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.0\n",
    "test = play_game(verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.9257598  -0.12808648  0.67169048 -0.46612859 -1.24246901  5.51359058\n",
      "  -5.19300185  1.01586     2.75430468]\n",
      " [ 1.73272651 -0.90027208  2.97492357 -0.76716662 -2.69652687  3.08612168\n",
      "  -1.5684573  -3.09438909  1.2330402 ]\n",
      " [-0.53691396  0.8506162  -1.9221383   1.62784548 -2.74632659  2.66225984\n",
      "  -1.06017609 -0.69583394  1.82066737]\n",
      " [ 1.88056057 -0.58182148 -2.22157024 -0.93973921 -2.29289809  4.598211\n",
      "  -4.42971036  1.65559914  2.33136868]\n",
      " [-1.41193656 -0.30103781  4.46352023  2.41074382 -6.91654863  3.13049463\n",
      "  -0.75365271 -1.33327531  0.71169234]\n",
      " [-0.19486346  1.47750293 -0.7810992   1.1693585   0.57564645 -0.82242128\n",
      "  -4.02281438  0.05167864  2.5470118 ]\n",
      " [-1.9737401  -0.15485452  2.55924902 -0.57359852 -0.91462379  3.60481575\n",
      "  -3.53194071 -0.82379213  1.80848501]\n",
      " [ 0.20398151  0.69563055 -1.09549952  2.536647   -2.79908921  2.29578348\n",
      "  -2.68699572 -0.80254082  1.65208273]\n",
      " [-4.33880452  1.64694909  4.70475007  3.31689319 -9.44965072  5.91526758\n",
      "   0.67899243 -1.96336741 -0.5110297 ]]\n",
      "[-0.03015157 -0.01571044 -0.00831973  0.02752672 -0.04248359  0.10328583\n",
      " -0.07905873  0.00230958  0.04260193]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(Xeps.T,yeps))\n",
    "print(np.mean(yeps, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
